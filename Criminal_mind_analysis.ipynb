{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praharshita1275/Criminal_mind_analysis/blob/main/Criminal_mind_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# path = \"https://drive.google.com/drive/folders/1KPv1lCH1Pol7HikFF7Qi8S5G3JbTACd3?usp=drive_link\n"
      ],
      "metadata": {
        "id": "I-dq_Ue5vdHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#viraj\n"
      ],
      "metadata": {
        "id": "XpUJ2Mh_usA2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## llm1\n"
      ],
      "metadata": {
        "id": "DgPScjN5JDUi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YKXoCA8lJGPk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "W4JHqgQ9wVU_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset\n",
        "\n",
        "df = pd.read_csv(\"/content/Crime_Data_from_2020_to_Present.csv\")\n",
        "\n",
        "df.head()\n",
        "df.info()\n",
        "df.isna().sum()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "id": "nEp_ZLN_wJMJ",
        "outputId": "a9b01216-5b21-4dfe-8c8a-c63e86113c99"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 326977 entries, 0 to 326976\n",
            "Data columns (total 13 columns):\n",
            " #   Column        Non-Null Count   Dtype  \n",
            "---  ------        --------------   -----  \n",
            " 0   DATE OCC      326977 non-null  object \n",
            " 1   TIME OCC      326977 non-null  int64  \n",
            " 2   AREA NAME     326977 non-null  object \n",
            " 3   Vict Age      326977 non-null  int64  \n",
            " 4   Vict Sex      326977 non-null  object \n",
            " 5   Vict Descent  326977 non-null  object \n",
            " 6   Premis Desc   326977 non-null  object \n",
            " 7   Weapon Desc   326977 non-null  object \n",
            " 8   Status Desc   326977 non-null  object \n",
            " 9   LOCATION      326977 non-null  object \n",
            " 10  LAT           326977 non-null  float64\n",
            " 11  LON           326977 non-null  float64\n",
            " 12  Crm Cd Desc   326977 non-null  object \n",
            "dtypes: float64(2), int64(2), object(9)\n",
            "memory usage: 32.4+ MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DATE OCC        0\n",
              "TIME OCC        0\n",
              "AREA NAME       0\n",
              "Vict Age        0\n",
              "Vict Sex        0\n",
              "Vict Descent    0\n",
              "Premis Desc     0\n",
              "Weapon Desc     0\n",
              "Status Desc     0\n",
              "LOCATION        0\n",
              "LAT             0\n",
              "LON             0\n",
              "Crm Cd Desc     0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>DATE OCC</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TIME OCC</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AREA NAME</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Vict Age</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Vict Sex</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Vict Descent</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Premis Desc</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weapon Desc</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Status Desc</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LOCATION</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LAT</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LON</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Crm Cd Desc</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#standardise column names\n",
        "\n",
        "df.columns = (\n",
        "    df.columns\n",
        "    .str.strip()\n",
        "    .str.lower()\n",
        "    .str.replace(\" \", \"_\")\n",
        "    .str.replace(r\"[^a-z0-9_]\", \"\", regex=True)\n",
        ")\n",
        "\n",
        "df.columns\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpqNcx_KwJEt",
        "outputId": "148f6efa-56a0-43e0-a382-1b7eeae23d5f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['date_occ', 'time_occ', 'area_name', 'vict_age', 'vict_sex',\n",
              "       'vict_descent', 'premis_desc', 'weapon_desc', 'status_desc', 'location',\n",
              "       'lat', 'lon', 'crm_cd_desc'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mUyjwmXVskfu"
      },
      "outputs": [],
      "source": [
        "#HANDLE MISSING & INVALID VALUES\n",
        "text_cols = [\n",
        "    \"area_name\", \"premis_desc\", \"weapon_desc\",\n",
        "    \"status_desc\", \"crm_cd_desc\", \"location\"\n",
        "]\n",
        "\n",
        "for col in text_cols:\n",
        "    df[col] = df[col].fillna(\"UNKNOWN\")\n",
        "\n",
        "df[\"vict_age\"] = df[\"vict_age\"].replace(0, np.nan)\n",
        "df[\"vict_age\"] = df[\"vict_age\"].fillna(\"UNKNOWN\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BASIC TEXT CLEANING (LIGHT)\n",
        "def clean_text(col):\n",
        "    return (\n",
        "        col.astype(str)\n",
        "        .str.lower()\n",
        "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
        "        .str.strip()\n",
        "    )\n",
        "\n",
        "for col in text_cols:\n",
        "    df[col] = clean_text(df[col])\n"
      ],
      "metadata": {
        "id": "q8LCIcUZw7QU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FIX DATE & TIME\n",
        "df[\"date_occ\"] = pd.to_datetime(df[\"date_occ\"], errors=\"coerce\")\n",
        "\n",
        "def time_to_hour(x):\n",
        "    try:\n",
        "        x = int(x)\n",
        "        return x // 100\n",
        "    except:\n",
        "        return \"UNKNOWN\"\n",
        "\n",
        "df[\"time_hour\"] = df[\"time_occ\"].apply(time_to_hour)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QburypRfw85M",
        "outputId": "abeb76e7-77a8-439f-bc00-6f3bb00131e8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1132658626.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df[\"date_occ\"] = pd.to_datetime(df[\"date_occ\"], errors=\"coerce\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SELECT ONLY USEFUL COLUMNS\n",
        "keep_cols = [\n",
        "    \"date_occ\", \"time_hour\", \"area_name\",\n",
        "    \"vict_age\", \"vict_sex\",\n",
        "    \"premis_desc\", \"weapon_desc\",\n",
        "    \"status_desc\", \"crm_cd_desc\",\n",
        "    \"location\"\n",
        "]\n",
        "\n",
        "df = df[keep_cols]\n",
        "\n"
      ],
      "metadata": {
        "id": "vcOXqfDrE_g1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATE THE MOST IMPORTANT COLUMN (crime_text)\n",
        "\"\"\" important step \"\"\"\n",
        "def create_crime_text(row):\n",
        "    return (\n",
        "        f\"On {row['date_occ'].date()} at {row['time_hour']} hours, \"\n",
        "        f\"in {row['area_name']} area, a {row['vict_age']}-year-old \"\n",
        "        f\"{row['vict_sex']} was involved in {row['crm_cd_desc']} \"\n",
        "        f\"at {row['premis_desc']}. \"\n",
        "        f\"Weapon used: {row['weapon_desc']}. \"\n",
        "        f\"Case status: {row['status_desc']}.\"\n",
        "    )\n",
        "\n",
        "df[\"crime_text\"] = df.apply(create_crime_text, axis=1)\n"
      ],
      "metadata": {
        "id": "gZfkMHL9xCr-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"crime_text\"].head(3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "_gkRgMRjxFhV",
        "outputId": "ab83cbcb-46f5-4b0d-ce7f-ed223ed1bbaf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    On 2020-05-10 at 22 hours, in central area, a ...\n",
              "1    On 2020-12-02 at 22 hours, in 77th street area...\n",
              "2    On 2020-05-01 at 23 hours, in 77th street area...\n",
              "Name: crime_text, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>crime_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>On 2020-05-10 at 22 hours, in central area, a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>On 2020-12-02 at 22 hours, in 77th street area...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>On 2020-05-01 at 23 hours, in 77th street area...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ADD SIMPLE RULE-BASED MOTIVATION LABEL\n",
        "def infer_motivation(crime):\n",
        "    crime = crime.lower()\n",
        "    if \"robbery\" in crime or \"theft\" in crime:\n",
        "        return \"financial\"\n",
        "    elif \"intimate partner\" in crime or \"rape\" in crime:\n",
        "        return \"emotional\"\n",
        "    elif \"assault\" in crime or \"weapon\" in crime:\n",
        "        return \"power\"\n",
        "    else:\n",
        "        return \"unknown\"\n",
        "\n",
        "df[\"initial_motivation\"] = df[\"crm_cd_desc\"].apply(infer_motivation)\n"
      ],
      "metadata": {
        "id": "IPw1WKV7xKlf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(df[\"crime_text\"][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mclhr2X9xNks",
        "outputId": "92251316-1cab-41bf-ac0e-4f9050fe9b33"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On 2020-12-02 at 22 hours, in 77th street area, a 21.0-year-old M was involved in robbery at street. Weapon used: verbal threat. Case status: invest cont.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save processed data as CSV\n",
        "df.to_csv(\"processed_crime_data.csv\", index=False)\n",
        "\n",
        "# -------------------------------\n",
        "# Prepare JSON data for LLM usage\n",
        "# -------------------------------\n",
        "\n",
        "llm_data = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    llm_data.append({\n",
        "        \"text\": row[\"crime_text\"],\n",
        "        \"area\": row[\"area_name\"],\n",
        "        \"crime_type\": row[\"crm_cd_desc\"],\n",
        "        \"weapon\": row[\"weapon_desc\"],\n",
        "        \"motivation_hint\": row[\"initial_motivation\"]\n",
        "    })\n",
        "\n",
        "# Save LLM-ready JSON file\n",
        "import json\n",
        "\n",
        "with open(\"crime_data_llm_ready.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(llm_data, f, indent=2, ensure_ascii=False)\n"
      ],
      "metadata": {
        "id": "j3uMgFHrxmp0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "# ============================================\n",
        "# STEP 11 — LOAD LLM-READY JSON\n",
        "# ============================================\n",
        "\n",
        "import json\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Load preprocessed data\n",
        "with open(\"crime_data_llm_ready.json\", \"r\") as f:\n",
        "    llm_data = json.load(f)\n",
        "\n",
        "# Sanity check\n",
        "print(\"Sample record:\")\n",
        "print(llm_data[0])\n",
        "print(\"-\" * 50)\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# STEP 12 — ZERO-SHOT CRIME CLASSIFICATION (LLM-1)\n",
        "# ============================================\n",
        "\n",
        "classifier = pipeline(\n",
        "    \"zero-shot-classification\",\n",
        "    model=\"facebook/bart-large-mnli\"\n",
        ")\n",
        "\n",
        "candidate_labels = [\n",
        "    \"violent crime\",\n",
        "    \"financial crime\",\n",
        "    \"sexual crime\",\n",
        "    \"domestic violence\",\n",
        "    \"property crime\",\n",
        "    \"non criminal\"\n",
        "]\n",
        "\n",
        "# Test on one sample first\n",
        "sample_text = llm_data[0][\"text\"]\n",
        "sample_result = classifier(sample_text, candidate_labels)\n",
        "\n",
        "print(\"Zero-shot test result:\")\n",
        "print(sample_result)\n",
        "print(\"-\" * 50)\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# STEP 13 — ATTACH LLM-1 OUTPUT TO DATA\n",
        "# ============================================\n",
        "\n",
        "for item in llm_data:\n",
        "    res = classifier(item[\"text\"], candidate_labels)\n",
        "    item[\"llm1_predicted_category\"] = res[\"labels\"][0]\n",
        "    item[\"llm1_score\"] = res[\"scores\"][0]\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# STEP 14 — SEMANTIC SIMILARITY (PATTERN SCORING)\n",
        "# ============================================\n",
        "\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Crime motivation prototypes\n",
        "prototypes = {\n",
        "    \"financial\": [\n",
        "        \"robbery for money\",\n",
        "        \"stealing cash\",\n",
        "        \"financial gain from theft\"\n",
        "    ],\n",
        "    \"emotional\": [\n",
        "        \"domestic dispute\",\n",
        "        \"relationship conflict\",\n",
        "        \"crime due to emotional distress\"\n",
        "    ],\n",
        "    \"power\": [\n",
        "        \"assault using weapon\",\n",
        "        \"threatening with force\",\n",
        "        \"crime to show dominance\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Encode prototype embeddings\n",
        "proto_embeds = {\n",
        "    label: embedder.encode(texts, convert_to_tensor=True)\n",
        "    for label, texts in prototypes.items()\n",
        "}\n",
        "\n",
        "# Compute semantic similarity\n",
        "for item in llm_data:\n",
        "    text_emb = embedder.encode(item[\"text\"], convert_to_tensor=True)\n",
        "\n",
        "    best_label = None\n",
        "    best_score = 0.0\n",
        "\n",
        "    for label, proto_emb in proto_embeds.items():\n",
        "        score = torch.max(util.cos_sim(text_emb, proto_emb)).item()\n",
        "        if score > best_score:\n",
        "            best_label = label\n",
        "            best_score = score\n",
        "\n",
        "    item[\"semantic_pattern\"] = best_label\n",
        "    item[\"semantic_score\"] = best_score\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# SAVE UPDATED DATASET\n",
        "# ============================================\n",
        "\n",
        "with open(\"crime_data_llm1_enriched.json\", \"w\") as f:\n",
        "    json.dump(llm_data, f, indent=2)\n",
        "\n",
        "print(\"LLM-1 enrichment complete.\")\n",
        "print(\"Saved as crime_data_llm1_enriched.json\")\n",
        "\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "Fp1MgX1xGR0g",
        "outputId": "3304e9fd-e5ae-4e96-d97d-5f0811616497"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n# ============================================\\n# STEP 11 — LOAD LLM-READY JSON\\n# ============================================\\n\\nimport json\\nimport torch\\nfrom transformers import pipeline\\nfrom sentence_transformers import SentenceTransformer, util\\n\\n# Load preprocessed data\\nwith open(\"crime_data_llm_ready.json\", \"r\") as f:\\n    llm_data = json.load(f)\\n\\n# Sanity check\\nprint(\"Sample record:\")\\nprint(llm_data[0])\\nprint(\"-\" * 50)\\n\\n\\n# ============================================\\n# STEP 12 — ZERO-SHOT CRIME CLASSIFICATION (LLM-1)\\n# ============================================\\n\\nclassifier = pipeline(\\n    \"zero-shot-classification\",\\n    model=\"facebook/bart-large-mnli\"\\n)\\n\\ncandidate_labels = [\\n    \"violent crime\",\\n    \"financial crime\",\\n    \"sexual crime\",\\n    \"domestic violence\",\\n    \"property crime\",\\n    \"non criminal\"\\n]\\n\\n# Test on one sample first\\nsample_text = llm_data[0][\"text\"]\\nsample_result = classifier(sample_text, candidate_labels)\\n\\nprint(\"Zero-shot test result:\")\\nprint(sample_result)\\nprint(\"-\" * 50)\\n\\n\\n# ============================================\\n# STEP 13 — ATTACH LLM-1 OUTPUT TO DATA\\n# ============================================\\n\\nfor item in llm_data:\\n    res = classifier(item[\"text\"], candidate_labels)\\n    item[\"llm1_predicted_category\"] = res[\"labels\"][0]\\n    item[\"llm1_score\"] = res[\"scores\"][0]\\n\\n\\n# ============================================\\n# STEP 14 — SEMANTIC SIMILARITY (PATTERN SCORING)\\n# ============================================\\n\\nembedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\\n\\n# Crime motivation prototypes\\nprototypes = {\\n    \"financial\": [\\n        \"robbery for money\",\\n        \"stealing cash\",\\n        \"financial gain from theft\"\\n    ],\\n    \"emotional\": [\\n        \"domestic dispute\",\\n        \"relationship conflict\",\\n        \"crime due to emotional distress\"\\n    ],\\n    \"power\": [\\n        \"assault using weapon\",\\n        \"threatening with force\",\\n        \"crime to show dominance\"\\n    ]\\n}\\n\\n# Encode prototype embeddings\\nproto_embeds = {\\n    label: embedder.encode(texts, convert_to_tensor=True)\\n    for label, texts in prototypes.items()\\n}\\n\\n# Compute semantic similarity\\nfor item in llm_data:\\n    text_emb = embedder.encode(item[\"text\"], convert_to_tensor=True)\\n\\n    best_label = None\\n    best_score = 0.0\\n\\n    for label, proto_emb in proto_embeds.items():\\n        score = torch.max(util.cos_sim(text_emb, proto_emb)).item()\\n        if score > best_score:\\n            best_label = label\\n            best_score = score\\n\\n    item[\"semantic_pattern\"] = best_label\\n    item[\"semantic_score\"] = best_score\\n\\n\\n# ============================================\\n# SAVE UPDATED DATASET\\n# ============================================\\n\\nwith open(\"crime_data_llm1_enriched.json\", \"w\") as f:\\n    json.dump(llm_data, f, indent=2)\\n\\nprint(\"LLM-1 enrichment complete.\")\\nprint(\"Saved as crime_data_llm1_enriched.json\")\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h7wQkNiFJHXn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## llm2\n"
      ],
      "metadata": {
        "id": "OL5J_tTUJIIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# ===============================\n",
        "# STEP 1: Load Murder Motives Data\n",
        "# ===============================\n",
        "df = pd.read_csv(\"/content/Murder Motives.csv\")\n",
        "\n",
        "# ===============================\n",
        "# STEP 2: Clean Column Names\n",
        "# ===============================\n",
        "df.columns = (\n",
        "    df.columns.str.lower()\n",
        "              .str.replace(\" \", \"_\")\n",
        "              .str.replace(\"/\", \"_\")\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# STEP 3: Verify Column Names\n",
        "# ===============================\n",
        "# Check if the necessary column exists\n",
        "required_columns = [\n",
        "    \"gain\",\n",
        "    \"property_dispute\",\n",
        "    \"personal_vendetta_or_enemity\",\n",
        "    \"love_affairs_sexual_relations\",\n",
        "    \"dowry\",\n",
        "    \"communalism\",\n",
        "    \"casteism\",\n",
        "    \"political_reasons\",\n",
        "    \"terrorists_extremists\",\n",
        "    \"other_causes\"\n",
        "]\n",
        "\n",
        "# Print the actual column names in the DataFrame to debug\n",
        "print(\"Actual column names in the DataFrame:\", df.columns)\n",
        "\n",
        "# Check if the required columns exist in the DataFrame\n",
        "missing_cols = [col for col in required_columns if col not in df.columns]\n",
        "if missing_cols:\n",
        "    print(f\"Warning: The following columns are missing in the dataset: {missing_cols}\")\n",
        "else:\n",
        "    print(\"All required columns are present.\")\n",
        "\n",
        "# ===============================\n",
        "# STEP 4: Remove Aggregate Rows\n",
        "# ===============================\n",
        "df = df[~df[\"state\"].str.contains(\"TOTAL\", na=False)]\n",
        "\n",
        "# ===============================\n",
        "# STEP 5: Identify Motivation Columns (LLM-2)\n",
        "# ===============================\n",
        "# Ensure the column names match with the cleaned names\n",
        "motivation_cols = [\n",
        "    \"gain\",\n",
        "    \"property_dispute\",\n",
        "    \"personal_vendetta_or_enemity\",\n",
        "    \"love_affairs_sexual_relations\",  # This should match the column name exactly\n",
        "    \"dowry\",\n",
        "    \"communalism\",\n",
        "    \"casteism\",\n",
        "    \"political_reasons\",\n",
        "    \"terrorists_extremists\",\n",
        "    \"other_causes\"\n",
        "]\n",
        "\n",
        "# ===============================\n",
        "# STEP 6: Convert Each Row to Motivation Profile\n",
        "# ===============================\n",
        "llm2_data = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    # Build motivation profile for each row\n",
        "    motivation_profile = {\n",
        "        col: int(row[col]) if not pd.isna(row[col]) else 0\n",
        "        for col in motivation_cols if col in df.columns  # Ensure the column exists\n",
        "    }\n",
        "\n",
        "    llm2_data.append({\n",
        "        \"state\": row[\"state\"],\n",
        "        \"year\": row[\"year\"],\n",
        "        \"motivation_distribution\": motivation_profile\n",
        "    })\n",
        "\n",
        "# ===============================\n",
        "# STEP 7: Save LLM-2 Dataset\n",
        "# ===============================\n",
        "with open(\"llm2_motivation_dataset.json\", \"w\") as f:\n",
        "    json.dump(llm2_data, f, indent=2)\n",
        "\n",
        "print(\"✅ LLM-2 Motivation Dataset Created\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVjMOLDkJNjZ",
        "outputId": "6b9402e8-efa3-4c1b-eca8-859b655bcc6a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual column names in the DataFrame: Index(['state', 'year', 'gain', 'property_dispute',\n",
            "       'personal_vendetta_or_enemity', 'love_affairs__sexual_relations',\n",
            "       'dowry', 'lunacy', 'witchcraft', 'communalism', 'casteism',\n",
            "       'class_conflict', 'political_reasons', 'terrorists__extremists',\n",
            "       'other_causes', 'total'],\n",
            "      dtype='object')\n",
            "Warning: The following columns are missing in the dataset: ['love_affairs_sexual_relations', 'terrorists_extremists']\n",
            "✅ LLM-2 Motivation Dataset Created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ExEW0sApJmaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## llm 3"
      ],
      "metadata": {
        "id": "tIWRnI-PJJqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# ===============================\n",
        "# STEP 1: Load Chicago Crimes Data\n",
        "# ===============================\n",
        "df = pd.read_csv(\"/content/Chicago_Crimes_2022.csv\")\n",
        "\n",
        "# ===============================\n",
        "# STEP 2: Standardize Column Names\n",
        "# ===============================\n",
        "df.columns = (\n",
        "    df.columns.str.lower()\n",
        "              .str.replace(\" \", \"_\")\n",
        "              .str.replace(r\"[^a-z0-9_]\", \"\", regex=True)\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# STEP 3: Select Context-Relevant Columns (LLM-3)\n",
        "# ===============================\n",
        "llm3_cols = [\n",
        "    \"date\",\n",
        "    \"primary_type\",\n",
        "    \"description\",\n",
        "    \"location_description\",\n",
        "    \"arrest\",\n",
        "    \"domestic\",\n",
        "    \"beat\",\n",
        "    \"district\",\n",
        "    \"ward\",\n",
        "    \"community_area\",\n",
        "    \"year\",\n",
        "    \"latitude\",\n",
        "    \"longitude\"\n",
        "]\n",
        "\n",
        "df_llm3 = df[llm3_cols].fillna(\"UNKNOWN\")\n",
        "\n",
        "# ===============================\n",
        "# STEP 4: Create Context Narrative (Text for LLM)\n",
        "# ===============================\n",
        "def build_context_text(row):\n",
        "    return (\n",
        "        f\"In {row['year']}, a {row['primary_type']} incident occurred at a \"\n",
        "        f\"{row['location_description']} location. \"\n",
        "        f\"Domestic case: {row['domestic']}. \"\n",
        "        f\"Arrest made: {row['arrest']}. \"\n",
        "        f\"District {row['district']}, Beat {row['beat']}.\"\n",
        "    )\n",
        "\n",
        "df_llm3[\"context_text\"] = df_llm3.apply(build_context_text, axis=1)\n",
        "\n",
        "# ===============================\n",
        "# STEP 5: Convert to LLM-3 JSON Format\n",
        "# ===============================\n",
        "llm3_data = []\n",
        "\n",
        "for _, row in df_llm3.iterrows():\n",
        "    llm3_data.append({\n",
        "        \"context_text\": row[\"context_text\"],\n",
        "        \"crime_type\": row[\"primary_type\"],\n",
        "        \"location_type\": row[\"location_description\"],\n",
        "        \"domestic\": row[\"domestic\"],\n",
        "        \"arrest\": row[\"arrest\"],\n",
        "        \"district\": row[\"district\"],\n",
        "        \"year\": row[\"year\"]\n",
        "    })\n",
        "\n",
        "# ===============================\n",
        "# STEP 6: Save LLM-3 Dataset\n",
        "# ===============================\n",
        "with open(\"llm3_background_context.json\", \"w\") as f:\n",
        "    json.dump(llm3_data, f, indent=2)\n",
        "\n",
        "print(\"✅ LLM-3 Background & Context Dataset Created\")\n"
      ],
      "metadata": {
        "id": "-6Qs6lAtJOWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Praharshita"
      ],
      "metadata": {
        "id": "wQnh6Hvvuuzj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ctTgAm0Ju2KN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}